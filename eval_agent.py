from env import TrackingEnv
from dqn import DQNAgent
import cv2
import torch
import numpy as np

# í•™ìŠµëœ ì—ì´ì „íŠ¸ ë¶ˆëŸ¬ì˜¤ê¸°
agent = DQNAgent()
agent.model.load_state_dict(torch.load("dqn_model.pth"))  # ì €ì¥ëœ ëª¨ë¸ ë¶ˆëŸ¬ì˜¤ê¸°
agent.epsilon = 0.0  # ğŸ’¡ ëœë¤ ì—†ì´ Q-value ê¸°ë°˜ í–‰ë™ë§Œ

env = TrackingEnv(size=100)

for ep in range(5):  # 5ê°œì˜ ì—í”¼ì†Œë“œ ì‹œê°í™”
    state = env.reset()
    total_reward = 0

    for t in range(100):
        action = agent.select_action(state)
        next_state, reward, _ = env.step(action)
        total_reward += reward
        state = next_state

        # ì‹œê°í™”
        img = np.ones((100, 100, 3), dtype=np.uint8) * 255
        ax, ay, tx, ty = state.astype(int)

        img[ty, tx] = [0, 0, 255]   # íƒ€ê²Ÿ = ë¹¨ê°„ìƒ‰
        img[ay, ax] = [255, 0, 0]   # ì—ì´ì „íŠ¸ = íŒŒë€ìƒ‰

        img = cv2.resize(img, (500, 500), interpolation=cv2.INTER_NEAREST)
        cv2.imshow("DQN Agent Evaluation", img)
        if cv2.waitKey(30) == 27:
            break

    print(f"Eval Episode {ep}: Total Reward = {total_reward:.2f}")

cv2.destroyAllWindows()
